{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mine_wordnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mine_wordnet.py\n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import product,chain\n",
    "from collections import defaultdict\n",
    "import operator,json,csv\n",
    "\n",
    "def get_definitions(word):\n",
    "    '''\n",
    "    Takes a word as input and returns all definitions in the form of a\n",
    "    dictionary with the synset as keys and definition text as values.\n",
    "    '''\n",
    "    definitions = defaultdict()\n",
    "    for i,j in enumerate(wn.synsets(word)):\n",
    "        definitions[j] = j.definition()\n",
    "    return definitions\n",
    "\n",
    "def get_ontology(seed_syn,word,write_file=False):\n",
    "    '''\n",
    "    Takes word as input and returns two dictionaries. One with the list\n",
    "    of hypernym synsets and one with a list of hyponym synsets.\n",
    "    '''\n",
    "    hypernyms = defaultdict()\n",
    "    hyponyms = defaultdict()\n",
    "    for i,j in enumerate(wn.synsets(word)):\n",
    "        hypernyms[j] = \",\".join(list(chain(*[l.lemma_names() for l in j.hypernyms()])))\n",
    "        hyponyms[j] = \",\".join(list(chain(*[l.lemma_names() for l in j.hyponyms()])))\n",
    "\n",
    "    hypo_words = [hyponyms.values()[i].split(',') for i in range(len(hyponyms.values())) if hyponyms.values()[i]][0]\n",
    "    hypo_syns = [get_definitions(hypo_words[i]).keys()[0] for i in xrange(len(hypo_words))]\n",
    "    relevant_hypo_synsets = calc_seed_similarity(seed_syn,hypo_syns)\n",
    "    \n",
    "    # Write to file as feeder system to wolfram alpha api code\n",
    "    if write_file:\n",
    "        file_endpoint = \"data/\"+word+\"_hyponyms.csv\"\n",
    "        hypo_out = [str(relevant_hypo_synsets[i][0].lemma_names()[0]).replace('_',' ') for i in range(len(relevant_hypo_synsets))]        \n",
    "        print(hypo_out)         \n",
    "#             if i == 0:\n",
    "#                 with open(file_endpoint, 'w') as data_out:\n",
    "#                     csv.writer(hypo_out, data_out)\n",
    "#             else:\n",
    "#                 with open(file_endpoint, 'a+') as data_out:\n",
    "#                     csv.writer(hypo_out, data_out)\n",
    "                \n",
    "        with open(file_endpoint, \"w\") as output:\n",
    "            writer = csv.writer(output, lineterminator='\\n')\n",
    "#             for hypo in hypo_out:\n",
    "            writer.writerow(hypo_out) \n",
    "    \n",
    "    return hypernyms, relevant_hypo_synsets #hyponyms\n",
    "\n",
    "def calc_seed_similarity(seed_syn,topic_syns,threshold=.2):\n",
    "    '''\n",
    "    Using Wu-Palmer Similiarity compare a seed synset to a list of\n",
    "    topic synsets. If the similarity score is above the threshold\n",
    "    it is considered relevant and returned.\n",
    "    '''\n",
    "    similarity_scores = defaultdict()\n",
    "    for i in range(len(topic_syns)):\n",
    "        score = seed_syn.wup_similarity(topic_syns[i]) # Wu-Palmer Similarity\n",
    "        if score > threshold:\n",
    "            similarity_scores[topic_syns[i]] = score\n",
    "    return sorted(similarity_scores.items(), key=operator.itemgetter(1), reverse=True) \n",
    "\n",
    "def create_flashcard(card_front,card_back,mode='w'):\n",
    "    '''\n",
    "    Create a flashcard with the front and back of the card as input\n",
    "    arguments. By default a new data file will be written, but the mode\n",
    "    can be set to 'a' or 'a+' to append to an existing file.\n",
    "    '''\n",
    "    flashcard = {\"fcid\": 1,\n",
    "                 \"order\": 0,\n",
    "                 \"term\": card_front,\n",
    "                 \"definition\": card_back,\n",
    "                 \"hint\": \"\",\n",
    "                 \"example\": \"\",\n",
    "                 \"term_image\": None,\n",
    "                 \"hint_image\": None}\n",
    "    \n",
    "    # Save the data\n",
    "    file_endpoint = \"data/\"+card_front+\".json\"\n",
    "\n",
    "    if mode.startswith('a'):\n",
    "        with open(file_endpoint, 'a+') as data_out:\n",
    "            json.dump(',', data_out)\n",
    "            json.dump(flashcard, data_out)\n",
    "    else:\n",
    "        with open(file_endpoint, 'w') as data_out:\n",
    "            json.dump(flashcard, data_out) \n",
    "\n",
    "#### TODO: Not yet converted to real function\n",
    "# def get_synonyms(word):\n",
    "#     print \"THESAURUS\"\n",
    "#     print 50 * '*'\n",
    "#     for i,j in enumerate(wn.synsets(topic)):\n",
    "#         print \"Meaning\",i, \"NLTK ID:\", j.name()\n",
    "#         print \"Definition:\",j.definition()\n",
    "#         print \"Synonyms:\",  \", \".join(j.lemma_names())\n",
    "#         print\n",
    "\n",
    "# Start by providing seed word to filter out unrelated topics/words\n",
    "SEED = 'math'\n",
    "seed_syn = get_definitions(SEED).keys()[0]\n",
    "# print 'SEED: ',SEED\n",
    "# print seed_syn\n",
    "\n",
    "topic = 'triangle'\n",
    "topic_syns = get_definitions(topic)\n",
    "# print 'TOPIC: ',topic\n",
    "# print 'SYNSETS: ',topic_syns\n",
    "\n",
    "relevant_synsets = calc_seed_similarity(seed_syn,topic_syns.keys())\n",
    "# for i in range(len(relevant_synsets)):\n",
    "#     create_flashcard(topic,topic_syns[relevant_synsets[i][0]],mode='a+')\n",
    "\n",
    "hypers,hypos = get_ontology(seed_syn,topic,write_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oblique triangle', 'right triangle', 'obtuse triangle', 'acute triangle', 'wedge', 'equilateral triangle', 'scalene triangle', 'isosceles triangle']\r\n"
     ]
    }
   ],
   "source": [
    "!python mine_wordnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oblique triangle\n",
      "right triangle\n",
      "obtuse triangle\n",
      "acute triangle\n",
      "wedge\n",
      "equilateral triangle\n",
      "scalene triangle\n",
      "isosceles triangle\n"
     ]
    }
   ],
   "source": [
    "hypo_out = ['oblique triangle', 'right triangle', 'obtuse triangle', 'acute triangle', 'wedge', 'equilateral triangle', 'scalene triangle', 'isosceles triangle']\n",
    "\n",
    "for hypo in hypo_out:\n",
    "    print(hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
